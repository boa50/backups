{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import io\n",
    "import os\n",
    "from datetime import date, datetime\n",
    "import configparser\n",
    "\n",
    "import googleapiclient.discovery\n",
    "from googleapiclient.http import MediaFileUpload, MediaIoBaseDownload\n",
    "from google.oauth2 import service_account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obter o nome do arquivo dependendo de como está sendo executado\n",
    "Essa função auxilia a retornoar o *path* correto do arquivo independente se ele está sendo executado em um jupyter notebook ou pelo arquivo .py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_local_filename(filename):\n",
    "    try:\n",
    "        return os.path.join(os.path.dirname(__file__), filename)\n",
    "    except:\n",
    "        return filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura de variáveis de ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['config.ini']"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read(get_local_filename('config.ini'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = config['VARS']['PROJECT']\n",
    "DB_API_KEY = config['VARS']['DB_API_KEY']\n",
    "DB_PASSWORD = config['VARS']['DB_PASSWORD']\n",
    "EMAIL = config['VARS']['EMAIL']\n",
    "PASTA_ID = config['VARS']['PASTA_ID']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções auxiliares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obter os dados de documentos do firebase por uma url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dados(url, headers):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        raise BaseException('GET /tasks/ {}'.format(resp.status_code))\n",
    "        \n",
    "    try:\n",
    "        return response.json()['documents']\n",
    "    except:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obter os ids de acordo com documentos do firebase\n",
    "Esses ids obtidos serverm para auxiliar na geração de novas urls e percorrimento da árvore de documentos do firebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ids(documents):\n",
    "    ids = []\n",
    "    \n",
    "    for document in documents:\n",
    "        identifier = document['name'].split('/')[-1]\n",
    "        ids.append(identifier)\n",
    "        \n",
    "    return ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gera de json de dados atuais\n",
    "Obtenção dos dados do firebase, percorrendo toda a árvore definida através da variável dicio, para que esses dados possam ser avaliados e realizada a ação de backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backup_generate(dicio, backup, ids=[''], \n",
    "                    urls=[f'https://firestore.googleapis.com/v1/projects/{PROJECT}/databases/(default)/documents/'],\n",
    "                    page_size=200, headers={}):\n",
    "    chaves = list(dicio.keys())\n",
    "    for chave in chaves:\n",
    "        new_urls = []\n",
    "        new_ids = []\n",
    "        \n",
    "        for url in urls:\n",
    "            for identificador in ids:\n",
    "                new_url = url\n",
    "                \n",
    "                if identificador != '':\n",
    "                    new_url += f'/{identificador}/'\n",
    "                    \n",
    "                new_url += f'{chave}?pageSize=200'\n",
    "                \n",
    "                k = new_url.split('?')[0].split('/')\n",
    "                k = k[-3] + '-' + k[-2] + '-' + k[-1]\n",
    "                backup[k] = get_dados(new_url, headers)\n",
    "                \n",
    "                new_url = new_url.split('?')[0]\n",
    "                \n",
    "                new_urls.append(new_url)\n",
    "                new_ids.append(get_ids(backup[k]))\n",
    "                \n",
    "\n",
    "        if isinstance(dicio[chave], dict):\n",
    "            new_ids = [identifier for sublist in new_ids for identifier in sublist]\n",
    "            \n",
    "            backup_generate(dicio[chave], backup, ids=new_ids, urls=new_urls, headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obter data de arquivo de backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(arquivo_nome):\n",
    "    dt_txt = arquivo_nome.split('_')[1].split('.')[0]\n",
    "    dt = datetime.strptime(dt_txt, '%d-%m-%Y')\n",
    "    \n",
    "    return dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Realizar download de último arquivo de backup\n",
    "Através de um json de arquvos de backup e sua data, é realizado o download para a máquina local do último arquivo de backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_last_backup(backups, filename):\n",
    "    file_id = [k for k, v in sorted(backups.items(), key=lambda item: item[1])][-1]\n",
    "    \n",
    "    print(f'Último backup de {filename}: {backups[file_id]}')\n",
    "    \n",
    "    request = drive.files().get_media(fileId=file_id)\n",
    "    fh = io.FileIO(get_local_filename(filename), mode='wb')\n",
    "    downloader = MediaIoBaseDownload(fh, request)\n",
    "    done = False\n",
    "    while done is False:\n",
    "        status, done = downloader.next_chunk()\n",
    "        print(\"Download %d%%.\" % int(status.progress() * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Realizar o upload de arquivo no Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arquivo_upload(filename, pasta_id):\n",
    "    file_metadata = {\n",
    "        'name': filename,\n",
    "        'mimeType': 'application/json',\n",
    "        'parents': [pasta_id]\n",
    "    }\n",
    "    media = MediaFileUpload(get_local_filename(filename), mimetype='application/json')\n",
    "\n",
    "    file = drive.files().create(body=file_metadata, media_body=media, fields='id').execute()\n",
    "    \n",
    "    print(f'Upload de arquivo realizado: {filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento da autenticação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "authUrl = f'https://identitytoolkit.googleapis.com/v1/accounts:signInWithPassword?key={DB_API_KEY}'\n",
    "\n",
    "authData = {\n",
    "    'email': EMAIL,\n",
    "    'password': DB_PASSWORD,\n",
    "    'returnSecureToken': True,\n",
    "};\n",
    "\n",
    "resp = requests.post(authUrl, data=json.dumps(authData))\n",
    "if resp.status_code != 200:\n",
    "    raise BaseException('GET /tasks/ {}'.format(resp.status_code))\n",
    "    \n",
    "id_token = resp.json()['idToken']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'Authorization': f'Bearer {id_token}'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criar dicionário da estrutura\n",
    "É feita a criação da estrutura de documentos do firebase em que, enquanto houver um elemento *dict* como valor, o algoritimo irá percorrer para buscar uma nova estrutura\n",
    "\n",
    "Um exemplo de estrutura seria:\n",
    "```\n",
    "{\n",
    "  'nivel1.1': {\n",
    "     'nivel1.1-2.1': {\n",
    "        'nivel1.1-2.2-3: 0\n",
    "     },\n",
    "     'nivel1.1-2.2: 0\n",
    "  },\n",
    "  'nivel1.2': 0\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicio = {\n",
    "    'familias': {\n",
    "        'aniversariantes': 0\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obter os dados atuais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "backup = {}\n",
    "backup_generate(dicio, backup, headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obter o útlimo backup salvo no Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCOPES = ['https://www.googleapis.com/auth/drive']\n",
    "SERVICE_ACCOUNT_FILE = get_local_filename('client_secret.json')\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "        SERVICE_ACCOUNT_FILE, scopes=SCOPES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive = googleapiclient.discovery.build('drive', 'v3', credentials=credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"'{PASTA_ID}' in parents\"\n",
    "res = drive.files().list(q=query, fields=\"files(id, name)\").execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "backups = {}\n",
    "\n",
    "arquivos = res.get('files', [])\n",
    "for arquivo in arquivos:\n",
    "    backups[arquivo['id']] = get_data(arquivo['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Último backup de backup.json: 2020-01-01 00:00:00\n",
      "Download 100%.\n"
     ]
    }
   ],
   "source": [
    "backup_filename = 'backup.json'\n",
    "\n",
    "download_last_backup(backups, backup_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realizar upload de novo backup\n",
    "É realizada a verificação se houve alteração das informações contidas no firebase em relação às informações do último arquivo de backup salvo e, em caso positivo, uma nova versão é salva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_atual = date.today().strftime(\"%d-%m-%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "ultimo_backup = {}\n",
    "\n",
    "with open(get_local_filename(backup_filename)) as json_file:\n",
    "    ultimo_backup = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup de gerado: backup_31-07-2020.json\n",
      "Upload de arquivo realizado: backup_31-07-2020.json\n"
     ]
    }
   ],
   "source": [
    "if backup != ultimo_backup:\n",
    "\n",
    "    filename = f'backup_{data_atual}.json'\n",
    "    with open(get_local_filename(filename), 'w') as outfile:\n",
    "        json.dump(backup, outfile)\n",
    "        print(f'Backup de gerado: {filename}')\n",
    "    \n",
    "    arquivo_upload(filename, PASTA_ID)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
